{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Extraction\n",
    "\n",
    "In this notebook we demonstrate how to encode features into machine-readable representation (i.e. numeric vectors).\n",
    "\n",
    "We first build vocabularies based on word frequences, character frequences and parts-of-speech tags. We then apply pre-processing over our dataset and map the examples into vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "# import the pre-processing functions\n",
    "from processing import text as text_prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read datasets\n",
    "toxic = pd.read_csv('datasets/toxic_comments.csv', encoding='utf-8')\n",
    "non_toxic = pd.read_csv('datasets/non_toxic_comments.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of raw comments\n",
    "comments = np.concatenate([non_toxic['comment'].unique(), toxic['comment'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159436,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"This: :One can make an analogy in mathematical terms by envisioning the distribution of opinions in a population as a Gaussian curve. We would then say that the consensus would be a statement that represents the range of opinions within perhaps three standard deviations of the mean opinion.  sounds arbitrary and ad hoc.  Does it really belong in n encyclopedia article?  I don't see that it adds anything useful.  The paragraph that follows seems much more useful.  Are there any political theorists out there who can clarify the issues?  It seems to me that this is an issue that Locke, Rousseau, de Toqueville, and others must have debated...  SR \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Vector\n",
    "\n",
    "Build the word frequences vocabulary and the function which apply pre-processing on a given text and maps it to the semantic vocabulary to produce the semantic vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-processing pipeline\n",
    "pipeline = [\n",
    "    text_prepro.to_lower,\n",
    "    text_prepro.transliterate,\n",
    "    text_prepro.remove_tags,\n",
    "    text_prepro.tokenize_url,\n",
    "    text_prepro.alphanum\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello @foobar, VISIT my [site](http://foo.bar)\n",
      "[1]: hello @foobar, visit my [site](http://foo.bar)\n",
      "[2]: hello @foobar, visit my [site](http://foo.bar)\n",
      "[3]: hello foobar, visit my [site](http://foo.bar)\n",
      "[4]: hello foobar, visit my [site](__URL__)\n",
      "[5]: hello foobar visit my site __URL__\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = u'Hello @foobar, VISIT my [site](http://foo.bar)'\n",
    "print text\n",
    "for i, pipe in enumerate(pipeline, 1):\n",
    "    text = pipe(text)\n",
    "    print u'[{}]: {}'.format(i, text)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract word counts\n",
    "word_counts = Counter()\n",
    "for comment in comments:\n",
    "    for pipe in pipeline:\n",
    "        comment = pipe(comment)\n",
    "    word_counts.update(comment.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180929\n"
     ]
    }
   ],
   "source": [
    "print len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'the', 498552),\n",
       " (u'to', 298646),\n",
       " (u'i', 241659),\n",
       " (u'of', 225486),\n",
       " (u'and', 225296),\n",
       " (u'you', 219647),\n",
       " (u'a', 216811),\n",
       " (u'is', 177325),\n",
       " (u'that', 161825),\n",
       " (u'it', 149322)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 words\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'branco', 1),\n",
       " (u'\\u65b0\\u64b0\\u59d3\\u6c0f\\u9332', 1),\n",
       " (u'accoutns', 1),\n",
       " (u'queensborough', 1),\n",
       " (u'commagene', 1),\n",
       " (u'personal_attacks_', 1),\n",
       " (u'psone', 1),\n",
       " (u'classsssssssss', 1),\n",
       " (u'morihiro', 1),\n",
       " (u'downstep', 1)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bottom 10 words\n",
    "word_counts.most_common()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select words with more than 1 occurrence\n",
    "select = {k: v for k, v in word_counts.iteritems() if v > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign unique indexes to each word\n",
    "sorted_words = sorted(select.iteritems(), key=lambda (k, v): (v, k), reverse=True)\n",
    "word_indexes = {k: i for i, (k, _) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indexes['is']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1173"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indexes['damn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# semantic vector mapper\n",
    "def semantic_vector(text):\n",
    "    for pipe in pipeline:\n",
    "        text = pipe(text)\n",
    "    vector = np.zeros((len(word_indexes),), dtype=np.float32)\n",
    "    for w in text.split():\n",
    "        ind = word_indexes.get(w)\n",
    "        if ind is not None:\n",
    "            vector[ind] = 1.\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\" ::::That's reasonable enough; I just saw the conflict on this one page and not on the rest.  I don't know details of it either, and if I had noticed the rest I probably would have been suspicious also (like Mav, below).  Also like mav, though, I probably would have noted why I reverted any changes on the article's talk page.  Best,   \""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example text\n",
    "comments[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate vector\n",
    "vector = semantic_vector(comments[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87334,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector[word_indexes['enough']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter vector\n",
    "\n",
    "We generate a list of 1-gram characters from alphanumeric characters (0-9, a-z) and punctuations then map a given text's characters to this list to produce the letter vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import itertools\n",
    "\n",
    "# character 1-grams\n",
    "chars = list(set((string.letters + string.digits + string.punctuation).lower() + ' '))\n",
    "char_indexes = {c: i for i, c in enumerate(sorted(chars))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '\"': 2,\n",
       " '#': 3,\n",
       " '$': 4,\n",
       " '%': 5,\n",
       " '&': 6,\n",
       " \"'\": 7,\n",
       " '(': 8,\n",
       " ')': 9,\n",
       " '*': 10,\n",
       " '+': 11,\n",
       " ',': 12,\n",
       " '-': 13,\n",
       " '.': 14,\n",
       " '/': 15,\n",
       " '0': 16,\n",
       " '1': 17,\n",
       " '2': 18,\n",
       " '3': 19,\n",
       " '4': 20,\n",
       " '5': 21,\n",
       " '6': 22,\n",
       " '7': 23,\n",
       " '8': 24,\n",
       " '9': 25,\n",
       " ':': 26,\n",
       " ';': 27,\n",
       " '<': 28,\n",
       " '=': 29,\n",
       " '>': 30,\n",
       " '?': 31,\n",
       " '@': 32,\n",
       " '[': 33,\n",
       " '\\\\': 34,\n",
       " ']': 35,\n",
       " '^': 36,\n",
       " '_': 37,\n",
       " '`': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64,\n",
       " '{': 65,\n",
       " '|': 66,\n",
       " '}': 67,\n",
       " '~': 68}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# character mapper\n",
    "def letter_vector(text):\n",
    "    vector = np.zeros((len(char_indexes),), dtype=np.float32)\n",
    "    for c in text:\n",
    "        i = char_indexes.get(c)\n",
    "        if i is not None:\n",
    "            vector[i] = 1.\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_letter = letter_vector(comments[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_letter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
